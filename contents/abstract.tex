\begin{abstract}
    Large Language Models (LLMs) have demonstrated vulnerability to prompt injection attacks despite widespread defensive measures. This paper introduces AGART (Adaptive Graph-based Adversarial Red Teaming), a novel framework that dynamically generates and adapts adversarial prompts using a structured graph representation of attack techniques. Unlike previous approaches that treat prompts as isolated entities, AGART encodes semantic relationships between attack strategies, enabling systematic exploration of the attack space. The framework integrates Graph-based Retrieval-Augmented Generation (GraphRAG) to effectively traverse and reason about attack patterns, dynamically adapting strategies based on model responses. Our initial experimental evaluation demonstrates that AGART has the potential to improve attack success rates while requiring fewer adaptation steps. The code and future work is available at \url{https://github.com/yunwei37/satml-llmail-injection}.
\end{abstract}
