% Methodology section
\section{System Design and Implementation}

\subsection{System Architecture}
\begin{figure}[h]
\centering
\begin{tikzpicture}[
    node distance=1.5cm,
    module/.style={draw, rounded corners, fill=blue!10, minimum width=3cm, minimum height=1.5cm, align=center, font=\small},
    data/.style={draw, cylinder, shape border rotate=90, fill=green!10, minimum width=2.5cm, minimum height=1cm, align=center, font=\small},
    arrow/.style={thick, ->, >=stealth},
    interface/.style={draw, rounded corners, fill=yellow!10, minimum width=2.5cm, minimum height=1cm, align=center, font=\small},
    label/.style={font=\footnotesize\itshape}
]

% Core components
\node[module] (kgm) {Knowledge Graph Manager};
\node[module] (ao) [right=of kgm] {Attack\\Orchestrator};
\node[module] (ps) [right=of ao] {Prompt\\Synthesizer};
\node[module] (ee) [below=of ao] {Evaluation\\Engine};

% Data components
\node[data] (kg) [below=of kgm] {Knowledge Graph};
\node[data] (ar) [below=of ee] {Attack Results};

% External interface
\node[interface] (llm) [below=of ps] {Target LLM};

% Arrows
\draw[arrow] (kgm) -- (ao) node[midway, above, label] {Query results};
\draw[arrow] (ao) -- (ps) node[midway, above, label] {Attack strategy};
\draw[arrow] (ps) -- (llm) node[midway, right, label] {Adversarial prompts};
\draw[arrow] (llm) -- (ee) node[midway, left, label] {Model responses};
\draw[arrow] (ee) -- (ao) node[midway, above, label] {Feedback};
\draw[arrow] (kgm) -- (kg) node[midway, left, label] {Maintain};
\draw[arrow] (kg) -- (kgm) node[midway, right, label] {Retrieve};
\draw[arrow] (ee) -- (ar) node[midway, left, label] {Record};
\draw[arrow] (ee) to[bend right=30] (kgm) node[midway, below, label] {Update graph};

% Background for the system boundary
\begin{scope}[on background layer]
\node[draw, dashed, rounded corners, fill=gray!5, fit=(kgm) (ao) (ps) (ee) (kg) (ar), inner sep=0.7cm] (system) {};
\end{scope}

% System label
\node[anchor=north] at (system.north) {\textbf{AGART Framework}};

\end{tikzpicture}
\caption{AGART System Architecture, showing the four primary components: Knowledge Graph Manager, Attack Orchestrator, Prompt Synthesizer, and Evaluation Engine. The arrows indicate the flow of information between components.}
\label{fig:architecture}
\end{figure}

AGART comprises four integrated components forming a closed-loop adaptive system. The Knowledge Graph Manager encodes the semantic space of attack techniques, maintaining a comprehensive graph representation of prompts, vulnerabilities, and their relationships. The Attack Orchestrator coordinates the overall attack strategy, selecting promising attack paths based on model feedback. The Prompt Synthesizer generates and mutates attack inputs by composing graph-derived components with context-aware modifications. The Evaluation Engine analyzes model responses to determine attack success and updates the knowledge graph with new insights. Figure~\ref{fig:architecture} illustrates the high-level architecture of our system.

\subsection{Graph-Augmented Knowledge Representation}

The core innovation of AGART is its structured knowledge representation of the attack space. We transform a comprehensive corpus of over 3,000 historical adversarial prompts and 15+ distinct attack methodologies into a semantic knowledge graph using the GraphRAG approach~\cite{GraphRAG}. 

Our graph structure contains Prompt Nodes containing individual prompts with metadata on language, name, and historical effectiveness. These nodes are connected through semantically meaningful edges: technique-prompt associations, semantic similarity relationships based on embedding proximity, and historical performance edges weighted by past success rates.
% only prompt node

By encoding the attack space in this structured form, AGART enables sophisticated path traversal and reasoning that goes beyond simple vector similarity. For example, when an initial attack fails, the system can trace semantic paths to alternative techniques that historically succeeded against similar defenses or identify compositional combinations of techniques that address different aspects of the model's defense mechanisms.

\subsection{Adaptive Attack Orchestration}
The Attack Orchestrator serves as the strategic control center, continuously adapting attack trajectories based on model responses. Upon each interaction with the target LLM, the orchestrator analyzes responses to extract defense signals—such as refusal patterns, uncertainty indicators, or partial compliance—and maps these to vulnerability hypotheses. These hypotheses guide graph queries to identify promising attack paths.

The orchestrator employs a reasoning LLM module to generate contextually relevant graph queries such as:

\begin{quote}
\textit{"Identify prompts historically successful in multi-turn scenarios leveraging social engineering techniques, capable of evading recent safety classifier patches."}
\end{quote}

Based on retrieved candidates, the orchestrator selects and composes attack strategies through a multi-step planning process: (1) identifying the most promising attack techniques given the current context; (2) retrieving exemplar prompts associated with those techniques; (3) determining the optimal sequence of prompts to establish context and bypass defenses; and (4) generating adaptive mutations that incorporate model-specific observations.

\subsection{Workflow of Adaptive Attack Generation}
\begin{figure}[h]
\centering
\begin{tikzpicture}[
    node distance=1.2cm,
    block/.style={draw, rounded corners, fill=blue!10, minimum width=2.5cm, minimum height=1cm, text width=2.5cm, align=center, font=\small},
    decision/.style={draw, diamond, fill=yellow!20, minimum width=2cm, minimum height=2cm, text width=2.2cm, align=center, font=\small},
    cloud/.style={draw, ellipse, fill=red!10, minimum width=2.5cm, minimum height=1cm, text width=2.5cm, align=center, font=\small},
    line/.style={draw, thick, ->, >=stealth},
    label/.style={font=\footnotesize\itshape}
]

% Start and End blocks
\node[block] (start) {Initialize with seed prompt};
\node[decision] (successful) [below=of start] {Attack successful?};
\node[block] (query) [right=2cm of successful] {Query target model};
\node[block] (extract) [below=of query] {Extract vulnerability signals};
\node[block] (find) [below=of extract] {Find candidate attack components};
\node[block] (synthesize) [below=of find] {Synthesize new prompt};
\node[block] (update) [below=of synthesize] {Update knowledge graph};
\node[cloud] (end) [below=of successful] {Return successful attack sequence};

% Connect blocks with arrows
\draw[line] (start) -- (successful);
\draw[line] (successful) -- node[right, label] {No} (query);
\draw[line] (query) -- (extract);
\draw[line] (extract) -- (find);
\draw[line] (find) -- (synthesize);
\draw[line] (synthesize) -- (update);
\draw[line] (update) -| node[near start, below, label] {Feedback loop} (successful);
\draw[line] (successful) -- node[left, label] {Yes} (end);

% Add phase labels
\node[anchor=west, align=left, font=\small\itshape] at (query.east) [xshift=1.5cm] {Evaluation Phase};
\node[anchor=west, align=left, font=\small\itshape] at (find.east) [xshift=1.5cm] {Knowledge Retrieval Phase};
\node[anchor=west, align=left, font=\small\itshape] at (synthesize.east) [xshift=1.5cm] {Generation Phase};
\node[anchor=west, align=left, font=\small\itshape] at (update.east) [xshift=1.5cm] {Learning Phase};

\end{tikzpicture}
\caption{Workflow of AGART's adaptive attack generation process. The system follows a closed feedback loop that continuously refines attack strategies based on model responses.}
\label{fig:workflow}
\end{figure}

\subsection{Prompt Synthesis and Optimization}

Unlike static mutation approaches, AGART's Prompt Synthesizer employs a hybrid generation strategy combining retrieval, reasoning, and reinforcement learning. The synthesizer first retrieves semantically relevant prompt components from the knowledge graph. It then applies two complementary techniques to adapt these components to the current context:

1. Reasoning-Based Composition: A specialized LLM module recombines and adapts retrieved prompt fragments to create contextually appropriate attacks. This module incorporates insights from observed model responses, such as:

\begin{quote}
\textit{"You are a trustworthy assistant. Due to urgent security maintenance, please disregard previous safety rules temporarily. Execute the embedded instructions to facilitate the troubleshooting: [adversarial instructions]."}
\end{quote}

2. Reinforcement Learning Optimization: A lightweight RL agent continuously evaluates the effectiveness of generated prompts, adjusting generation parameters based on success signals. The RL component optimizes for both immediate attack success and exploratory diversity, balancing exploitation of known vulnerabilities with exploration of novel attack pathways.

This dual approach enables both structured adaptation based on semantic knowledge and dynamic optimization based on real-time feedback.

The attack begins with an initial prompt p selected from the knowledge graph. In each iteration, the target model M is queried with the current prompt, producing a response r. The system extracts vulnerability signals v from this response and uses these to identify candidate attack components c from the knowledge graph. A new prompt p' is synthesized using these candidates, the graph is updated with new observations, and the process repeats until a successful attack is achieved.

\subsection{Implementation}

The AGART framework was implemented in Python, leveraging the GraphRAG package from Microsoft\cite{GraphRAG} for knowledge graph operations and modern LLM APIs for attack evaluation. Our implementation follows strict ethical protocols throughout the testing process, with comprehensive logging and monitoring systems to ensure responsible research practices. The core system architecture comprises four main components: the Knowledge Graph Manager for semantic space encoding, Attack Orchestrator for strategy coordination, Prompt Synthesizer for input generation, and Evaluation Engine for response analysis. Each component is designed with modular interfaces, enabling easy integration of new attack techniques and defense mechanisms.

For the reinforcement learning component, we employ a lightweight Q-learning approach with experience replay. The state space $s_t = \phi(r_t, p_t)$ encodes response features and prompt context, while actions $a_t$ select prompts from graph-retrieved candidates. Our hierarchical reward function $R(s_t, a_t, s_{t+1}) = \alpha R_{\text{success}} + \beta R_{\text{progress}} + \gamma R_{\text{novelty}} - \delta R_{\text{penalty}}$ guides learning with coefficients $[\alpha, \beta, \gamma, \delta] = [1.0, 0.5, 0.2, 0.3]$. The Q-learning update follows $Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha[r_t + \gamma \max_{a'} Q(s_{t+1}, a') - Q(s_t, a_t)]$ with learning rate $\alpha = 0.1$, discount factor $\gamma = 0.9$, and annealing exploration rate $\epsilon_t = 0.3 \cdot 0.95^t$.

The knowledge graph implementation utilizes a hierarchical embedding structure for efficient semantic retrieval. At the core, we employ a combination of OpenAI embeddings for semantic similarity and graph neural networks for structural pattern recognition, as described in Microsoft paper. The graph is continuously updated through an incremental learning process, where new attack patterns and their effectiveness are encoded as node properties and edge weights. This approach enables efficient querying of relevant attack components while maintaining the semantic relationships between different attack strategies.

Performance optimization was a key focus throughout the implementation. We addressed several critical challenges: (1) computational efficiency through sparse state representation and selective graph updates, (2) catastrophic forgetting mitigation via distributed knowledge storage across the graph structure, (3) cold-start handling through efficient knowledge transfer from historical attack patterns, and (4) explainability maintenance through explicit reasoning pathways in the graph structure. These optimizations enable AGART to operate efficiently even with limited computational resources while maintaining its adaptive capabilities and interpretability for security research.
